{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7cXXRW2Xt2f_"
      },
      "source": [
        "# Install and load necesary packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hLdjx2cxt2gD"
      },
      "outputs": [],
      "source": [
        "# Please don't change this cell\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np  \n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKwx-ptlt2gF"
      },
      "source": [
        "## Load the dataset using pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QvDpXh8ot2gF"
      },
      "outputs": [],
      "source": [
        "# Please don't change this cell\n",
        "\n",
        "df = pd.read_csv('ml-100k/u.data', names=['user_id', 'item_id', 'rating', 'timestamp'], sep='\\t')\n",
        "\n",
        "# obtain top 500 users and top 500 items\n",
        "user_ids = df.groupby('user_id').count().sort_values(by='rating', ascending=False).head(500).index\n",
        "item_ids = df.groupby('item_id').count().sort_values(by='rating', ascending=False).head(500).index\n",
        "df = df[(df['user_id'].isin(user_ids)) & (df['item_id'].isin(item_ids))]\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PUZJeRo3t2gH"
      },
      "source": [
        "# Split dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yapm7HIDt2gH"
      },
      "source": [
        "## Randomly select one rating from each user as test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "79sL7X_Bt2gI"
      },
      "outputs": [],
      "source": [
        "# Please don't change this cell\n",
        "\n",
        "# remap user and item ID\n",
        "df['user_id'] = df.groupby('user_id').ngroup()\n",
        "df['item_id'] = df.groupby('item_id').ngroup()\n",
        "\n",
        "test_df = df.groupby('user_id').sample(1, random_state=1024)\n",
        "train_df = df[~df.index.isin(test_df.index)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XqcTePn1t2gJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "891da49e-4e56-4ffb-d488-cf3ff05abb6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of users: 500\n",
            "The number of items: 500\n",
            "Avg. # of rated Items/User: 129.914\n",
            "Density of data: 0.259828\n",
            "Ratings Range: 1 - 5\n"
          ]
        }
      ],
      "source": [
        "# Please don't change this cell\n",
        "\n",
        "n_users = df.user_id.unique().shape[0]\n",
        "n_items = df.item_id.unique().shape[0]\n",
        "avg_num = df.groupby('user_id').size().mean()\n",
        "density = df.shape[0] / (n_users * n_items)\n",
        "min_ratings = df.rating.min()\n",
        "max_ratings = df.rating.max()\n",
        "\n",
        "print(\"The number of users: {}\" .format(n_users))\n",
        "print(\"The number of items: {}\" .format(n_items))\n",
        "print(\"Avg. # of rated Items/User: {}\" .format(avg_num))\n",
        "print(\"Density of data: {}\" .format(density))\n",
        "print(\"Ratings Range: {} - {}\" .format(min_ratings, max_ratings))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M-pLkXm0t2gK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e3a342f-7a4a-45f4-f426-2ba4ad2c7dcb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Construct the rating matrix based on train_df:\n",
            "[[5. 3. 4. ... 0. 0. 0.]\n",
            " [4. 0. 0. ... 0. 0. 0.]\n",
            " [4. 3. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 5. 0. ... 0. 4. 0.]]\n",
            "Construct the rating matrix based on test_df:\n",
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n"
          ]
        }
      ],
      "source": [
        "# Please don't change this cell\n",
        "\n",
        "# Convert the format of datasets to matrices\n",
        "# Train dataset\n",
        "df_zeros = pd.DataFrame({\n",
        "    'user_id': np.tile(np.arange(0, n_users), n_items), \n",
        "    'item_id': np.repeat(np.arange(0, n_items), n_users), \n",
        "    'rating': 0})\n",
        "train_ds = df_zeros.merge(train_df, \n",
        "                          how='left', \n",
        "                          on=['user_id', 'item_id']).fillna(0.).pivot_table(\n",
        "                              values='rating_y', \n",
        "                              index='user_id', \n",
        "                              columns='item_id').values\n",
        "                           \n",
        "# Test dataset\n",
        "test_ds = df_zeros.merge(test_df, \n",
        "                         how='left', \n",
        "                         on=['user_id', 'item_id']).fillna(0.).pivot_table(\n",
        "                             values='rating_y', \n",
        "                             index='user_id', \n",
        "                             columns='item_id').values\n",
        "\n",
        "print(\"Construct the rating matrix based on train_df:\")\n",
        "print(train_ds)\n",
        "\n",
        "print(\"Construct the rating matrix based on test_df:\")\n",
        "print(test_ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X6swrbj1t2gL"
      },
      "source": [
        "# Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BpH3UMrBt2gL"
      },
      "outputs": [],
      "source": [
        "# Please don't change this cell\n",
        "EPSILON = 1e-9\n",
        "\n",
        "def user_corr(imputed_train_ds):\n",
        "    '''\n",
        "    Function for calculating user's similarity\n",
        "    '''\n",
        "    active_user_pearson_corr = np.zeros((imputed_train_ds.shape[0], imputed_train_ds.shape[0]))\n",
        "\n",
        "    # Compute Pearson Correlation Coefficient of All Pairs of Users between active set and training dataset\n",
        "    for i, user_i_vec in enumerate(imputed_train_ds):\n",
        "        for j, user_j_vec in enumerate(imputed_train_ds):\n",
        "\n",
        "            # ratings corated by the current pair od users\n",
        "            mask_i = user_i_vec > 0\n",
        "            mask_j = user_j_vec > 0\n",
        "\n",
        "            # corrated item index, skip if there are no corrated ratings\n",
        "            corrated_index = np.intersect1d(np.where(mask_i), np.where(mask_j))\n",
        "            if len(corrated_index) == 0:\n",
        "                continue\n",
        "\n",
        "            # average value of user_i_vec and user_j_vec\n",
        "            mean_user_i = np.sum(user_i_vec) / (np.sum(np.clip(user_i_vec, 0, 1)) + EPSILON)\n",
        "            mean_user_j = np.sum(user_j_vec) / (np.sum(np.clip(user_j_vec, 0, 1)) + EPSILON)\n",
        "\n",
        "            # compute pearson corr\n",
        "            user_i_sub_mean = user_i_vec[corrated_index] - mean_user_i\n",
        "            user_j_sub_mean = user_j_vec[corrated_index] - mean_user_j\n",
        "\n",
        "            r_ui_sub_r_i_sq = np.square(user_i_sub_mean)\n",
        "            r_uj_sub_r_j_sq = np.square(user_j_sub_mean)\n",
        "\n",
        "            r_ui_sum_sqrt = np.sqrt(np.sum(r_ui_sub_r_i_sq))\n",
        "            r_uj_sum_sqrt = np.sqrt(np.sum(r_uj_sub_r_j_sq))\n",
        "\n",
        "            sim = np.sum(user_i_sub_mean * user_j_sub_mean) / (r_ui_sum_sqrt * r_uj_sum_sqrt + EPSILON)\n",
        "            active_user_pearson_corr[i][j] = sim\n",
        "\n",
        "    return active_user_pearson_corr\n",
        "\n",
        "def predict(test_ds, imputed_train_ds, user_corr, k=20):\n",
        "    '''\n",
        "    Function for predicting ratings in test_ds\n",
        "    '''\n",
        "\n",
        "    # Predicting ratings of test set\n",
        "    predicted_ds = np.zeros_like(test_ds)\n",
        "\n",
        "    for (i, j), rating in np.ndenumerate(test_ds):\n",
        "\n",
        "        if rating > 0:\n",
        "\n",
        "            # only predict ratings on test set\n",
        "            sim_user_ids = np.argsort(user_corr[i])[-1:-(k + 1):-1]\n",
        "\n",
        "            #==================user-based==================#\n",
        "            # the coefficient values of similar users\n",
        "            sim_val = user_corr[i][sim_user_ids]\n",
        "\n",
        "            # the average value of the current user's ratings\n",
        "            sim_users = imputed_train_ds[sim_user_ids]\n",
        "            \n",
        "            mask_rateditem_user = imputed_train_ds[i] != 0\n",
        "            num_rated_items = mask_rateditem_user.astype(np.float32)\n",
        "            user_mean = np.sum(imputed_train_ds[i, mask_rateditem_user]) / (num_rated_items.sum() + EPSILON)\n",
        "\n",
        "            mask_nei_rated_items = sim_users != 0\n",
        "            num_rated_per_user = mask_nei_rated_items.astype(np.float32)\n",
        "            num_per_user = num_rated_per_user.sum(axis=1)\n",
        "\n",
        "            sum_per_user = sim_users.sum(axis=1)\n",
        "            sim_user_mean = sum_per_user / (num_per_user + EPSILON)\n",
        "            \n",
        "            mask_rated_j = sim_users[:, j] > 0\n",
        "                            \n",
        "            # sim(u, v) * (r_vj - mean_v)\n",
        "            sim_r_sum_mean = sim_val[mask_rated_j] * (sim_users[mask_rated_j, j] - sim_user_mean[mask_rated_j])\n",
        "            \n",
        "            user_based_pred = user_mean + np.sum(sim_r_sum_mean) / (np.sum(sim_val[mask_rated_j]) + EPSILON)\n",
        "\n",
        "            predicted_ds[i, j] = np.clip(user_based_pred, 0, 5)\n",
        "            \n",
        "    return predicted_ds\n",
        "\n",
        "def evaluate(test_ds, predicted_ds):\n",
        "    '''\n",
        "    Function for evaluating on MAE and RMSE\n",
        "    '''\n",
        "    # MAE\n",
        "    mask_test_ds = test_ds > 0\n",
        "    MAE = np.sum(np.abs(test_ds[mask_test_ds] - predicted_ds[mask_test_ds])) / np.sum(mask_test_ds.astype(np.float32))\n",
        "\n",
        "    # RMSE\n",
        "    RMSE = np.sqrt(np.sum(np.square(test_ds[mask_test_ds] - predicted_ds[mask_test_ds])) / np.sum(mask_test_ds.astype(np.float32)))\n",
        "\n",
        "    return MAE, RMSE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xduvdTdZt2gN"
      },
      "source": [
        "# Baseline - KNN based recommendation (Similarity Metric: Pearson Correlation Coefficient)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h19ek85_t2gN"
      },
      "outputs": [],
      "source": [
        "# Please don't change this cell\n",
        "\n",
        "user_pearson_corr = user_corr(train_ds)\n",
        "predicted_ds = predict(test_ds, train_ds, user_pearson_corr, k=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r8dVdwVht2gO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "466038f8-a9ec-4678-8cdb-369ee723e58a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===================== Baseline Result =====================\n",
            "MAE: 0.8471711011333851, RMSE: 1.092846045041526\n"
          ]
        }
      ],
      "source": [
        "# Please don't change this cell\n",
        "\n",
        "MAE, RMSE = evaluate(test_ds, predicted_ds)\n",
        "\n",
        "print(\"===================== Baseline Result =====================\")\n",
        "print(\"MAE: {}, RMSE: {}\" .format(MAE, RMSE))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eKCxgHFt2gO"
      },
      "source": [
        "# Your Solution\n",
        "(Put all your implementation for your solution in the following cell only)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0zJgk0cUt2gO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7c365e5-22ca-4589-d5aa-ddb84691106f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Density of data: 1.0\n"
          ]
        }
      ],
      "source": [
        "# Write your code here\n",
        "# You are required to implement the existing solution in the given report here. \n",
        "# Then, evaluate your implementation by predicting the ratings in the test set (test_ds).\n",
        "# Finally, save the corresponding MAE and RMSE of your implementation \n",
        "# into the following defined corresponding variable. \n",
        "\n",
        "MAE = 0 # 0 is an intial value, you need to update this with the actual perofrmance of your implementation.\n",
        "RMSE = 0 # 0 is an intial value, you need to update this with the actual perofrmance of your implementation.\n",
        "\n",
        "# To avoid messing up anything above\n",
        "dfc = df.drop(columns=['timestamp'])\n",
        "dfoutput = dfc.copy(deep=True)\n",
        "\n",
        "# Iterate through list of items\n",
        "for item in df.item_id.unique():\n",
        "\n",
        "  # Iterate through list of users\n",
        "  for user in df.user_id.unique():\n",
        "\n",
        "    # If a user does not have a rating for a particular item\n",
        "    if item not in dfc[dfc.user_id == user]['item_id'].values:\n",
        "\n",
        "      # Give the user a new rating of the item, where rating = average rating given out by that user\n",
        "      add = {'user_id': user, 'item_id': item, 'rating':dfc[dfc.user_id == user].rating.mean()}\n",
        "      dfoutput = dfoutput.append(add, ignore_index=True)\n",
        "\n",
        "# Data density verification, should be 1.0 assuming all the missing ratings are filled\n",
        "density = dfoutput.shape[0] / (dfoutput.user_id.unique().shape[0] * dfoutput.item_id.unique().shape[0])\n",
        "avg_num = dfoutput.groupby('user_id').size().mean()\n",
        "density = dfoutput.shape[0] / (n_users * n_items)\n",
        "min_ratings = dfoutput.rating.min()\n",
        "max_ratings = dfoutput.rating.max()\n",
        "\n",
        "print(\"The number of users: {}\" .format(n_users))\n",
        "print(\"The number of items: {}\" .format(n_items))\n",
        "print(\"Avg. # of rated Items/User: {}\" .format(avg_num))\n",
        "print(\"Density of data: {}\" .format(density))\n",
        "print(\"Ratings Range: {} - {}\" .format(min_ratings, max_ratings))\n",
        "\n",
        "# Operate on the new data\n",
        "dfoutput['user_id'] = dfoutput.groupby('user_id').ngroup()\n",
        "dfoutput['item_id'] = dfoutput.groupby('item_id').ngroup()\n",
        "\n",
        "test_dfo = dfoutput.groupby('user_id').sample(1, random_state=1024)\n",
        "train_dfo = dfoutput[~dfoutput.index.isin(test_dfo.index)]\n",
        "\n",
        "dfo_zeros = pd.DataFrame({\n",
        "    'user_id': np.tile(np.arange(0, n_users), n_items), \n",
        "    'item_id': np.repeat(np.arange(0, n_items), n_users), \n",
        "    'rating': 0})\n",
        "train_dso = dfo_zeros.merge(train_dfo, \n",
        "                          how='left', \n",
        "                          on=['user_id', 'item_id']).fillna(0.).pivot_table(\n",
        "                              values='rating_y', \n",
        "                              index='user_id', \n",
        "                              columns='item_id').values\n",
        "                           \n",
        "test_dso = dfo_zeros.merge(test_dfo, \n",
        "                         how='left', \n",
        "                         on=['user_id', 'item_id']).fillna(0.).pivot_table(\n",
        "                             values='rating_y', \n",
        "                             index='user_id', \n",
        "                             columns='item_id').values\n",
        "\n",
        "user_pearson_corr = user_corr(train_dso)\n",
        "predicted_dso = predict(test_dso, train_dso, user_pearson_corr, k=20)\n",
        "\n",
        "# Write new values in\n",
        "MAE, RMSE = evaluate(test_dso, predicted_dso)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_1T0aHZt2gP"
      },
      "source": [
        "## Print the MAE and RMSE of Your Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gS-HK0MOt2gP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6fa9fe4-7c3f-4d2c-efc6-cc8e0714619c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===================== The MAE and RMSE of Your Implementation =====================\n",
            "MAE: 0.263879522269567, RMSE: 0.4723215815156996\n"
          ]
        }
      ],
      "source": [
        "# Please don't change this cell\n",
        "\n",
        "print(\"===================== The MAE and RMSE of Your Implementation =====================\")\n",
        "print(\"MAE: {}, RMSE: {}\" .format(MAE, RMSE))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bbPmBaDNt2gP"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Assignment3_framework.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}